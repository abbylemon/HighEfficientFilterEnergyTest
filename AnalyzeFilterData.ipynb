{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import *\n",
    "import numpy as np\n",
    "#import peakutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abby/miniconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Filter ID</th>\n",
       "      <th>Install Time</th>\n",
       "      <th>Removal Time</th>\n",
       "      <th>Indoor Temp</th>\n",
       "      <th>Outdoor Temp</th>\n",
       "      <th>Outdoor RH</th>\n",
       "      <th>Pre 20x20x1</th>\n",
       "      <th>Post 20x20x1</th>\n",
       "      <th>Pre 14x24x1</th>\n",
       "      <th>Post 14x24x1</th>\n",
       "      <th>DAQ File</th>\n",
       "      <th>Install Date Time</th>\n",
       "      <th>Removal Date Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/20/19</td>\n",
       "      <td>FG-1</td>\n",
       "      <td>14:10</td>\n",
       "      <td>16:12</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191120134426</td>\n",
       "      <td>2019-11-20 14:10:00</td>\n",
       "      <td>2019-11-20 16:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/20/19</td>\n",
       "      <td>FG-2</td>\n",
       "      <td>16:16</td>\n",
       "      <td>6:13</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191120134426</td>\n",
       "      <td>2019-11-20 16:16:00</td>\n",
       "      <td>2019-11-21 06:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/21/19</td>\n",
       "      <td>MERV 8-1</td>\n",
       "      <td>8:02</td>\n",
       "      <td>10:18</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191121080221.dld.0000,1</td>\n",
       "      <td>2019-11-21 08:02:00</td>\n",
       "      <td>2019-11-21 10:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/21/19</td>\n",
       "      <td>MERV 8-2</td>\n",
       "      <td>10:18</td>\n",
       "      <td>12:38</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191121080221.dld.0000,1</td>\n",
       "      <td>2019-11-21 10:18:00</td>\n",
       "      <td>2019-11-21 12:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/21/19</td>\n",
       "      <td>MERV 13-1</td>\n",
       "      <td>12:38</td>\n",
       "      <td>14:46</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191121080221.dld.0000,1</td>\n",
       "      <td>2019-11-21 12:38:00</td>\n",
       "      <td>2019-11-21 14:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/21/19</td>\n",
       "      <td>MERV 13-2</td>\n",
       "      <td>14:46</td>\n",
       "      <td>16:58</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191121080221.dld.0000,1</td>\n",
       "      <td>2019-11-21 14:46:00</td>\n",
       "      <td>2019-11-21 16:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11/21/19</td>\n",
       "      <td>MERV 8-4</td>\n",
       "      <td>16:58</td>\n",
       "      <td>5:30</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>7.1 oz.</td>\n",
       "      <td>7.1 oz.</td>\n",
       "      <td>7.5 oz.</td>\n",
       "      <td>7.5 oz.</td>\n",
       "      <td>Data-20191121080221.dld.0000,1</td>\n",
       "      <td>2019-11-21 16:58:00</td>\n",
       "      <td>2019-11-22 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11/22/19</td>\n",
       "      <td>MERV 8-5</td>\n",
       "      <td>7:51</td>\n",
       "      <td>10:04</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>7.2 oz.</td>\n",
       "      <td>7.25 oz.</td>\n",
       "      <td>7.55 oz.</td>\n",
       "      <td>7.55 oz.</td>\n",
       "      <td>Data-20191122074415</td>\n",
       "      <td>2019-11-22 07:51:00</td>\n",
       "      <td>2019-11-22 10:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11/22/19</td>\n",
       "      <td>MERV 13-4</td>\n",
       "      <td>10:04</td>\n",
       "      <td>13:00</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>8.55 oz.</td>\n",
       "      <td>8.55 oz.</td>\n",
       "      <td>8 oz.</td>\n",
       "      <td>7.55 oz.</td>\n",
       "      <td>Data-20191122074415</td>\n",
       "      <td>2019-11-22 10:04:00</td>\n",
       "      <td>2019-11-22 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11/22/19</td>\n",
       "      <td>MERV 13-5</td>\n",
       "      <td>13:00</td>\n",
       "      <td>15:32</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>8.6 oz.</td>\n",
       "      <td>8.6 oz.</td>\n",
       "      <td>8.05 oz.</td>\n",
       "      <td>8.05 oz.</td>\n",
       "      <td>Data-20191122074415</td>\n",
       "      <td>2019-11-22 13:00:00</td>\n",
       "      <td>2019-11-22 15:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11/25/19</td>\n",
       "      <td>FG-1</td>\n",
       "      <td>7:40</td>\n",
       "      <td>9:44</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191125071926.dld.0000,1</td>\n",
       "      <td>2019-11-25 07:40:00</td>\n",
       "      <td>2019-11-25 09:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11/25/19</td>\n",
       "      <td>FG-2</td>\n",
       "      <td>9:44</td>\n",
       "      <td>13:47</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191125071926.dld.0000,1</td>\n",
       "      <td>2019-11-25 09:44:00</td>\n",
       "      <td>2019-11-25 13:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11/25/19</td>\n",
       "      <td>MERV 8-1</td>\n",
       "      <td>13:47</td>\n",
       "      <td>17:46</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191125071926.dld.0000,1</td>\n",
       "      <td>2019-11-25 13:47:00</td>\n",
       "      <td>2019-11-25 17:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11/25/19</td>\n",
       "      <td>MERV 8-2</td>\n",
       "      <td>17:46</td>\n",
       "      <td>6:25</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191125071926.dld.0000,1</td>\n",
       "      <td>2019-11-25 17:46:00</td>\n",
       "      <td>2019-11-26 06:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/26/19</td>\n",
       "      <td>MERV 13-1</td>\n",
       "      <td>6:25</td>\n",
       "      <td>9:43</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191126061705.dld.0000</td>\n",
       "      <td>2019-11-26 06:25:00</td>\n",
       "      <td>2019-11-26 09:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11/26/19</td>\n",
       "      <td>MERV 13-2</td>\n",
       "      <td>9:43</td>\n",
       "      <td>13:03</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191126061705.dld.0000</td>\n",
       "      <td>2019-11-26 09:43:00</td>\n",
       "      <td>2019-11-26 13:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11/26/19</td>\n",
       "      <td>MERV 8-4</td>\n",
       "      <td>13:03</td>\n",
       "      <td>16:47</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>7.15 oz.</td>\n",
       "      <td>7.15 oz.</td>\n",
       "      <td>7.5 oz.</td>\n",
       "      <td>7.5 oz.</td>\n",
       "      <td>Data-20191126061705.dld.0000</td>\n",
       "      <td>2019-11-26 13:03:00</td>\n",
       "      <td>2019-11-26 16:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11/26/19</td>\n",
       "      <td>MERV 8-5</td>\n",
       "      <td>16:47</td>\n",
       "      <td>5:37</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>7.2 oz.</td>\n",
       "      <td>7.2 oz.</td>\n",
       "      <td>7.55 oz.</td>\n",
       "      <td>7.55 oz.</td>\n",
       "      <td>Data-20191126061705.dld.0000</td>\n",
       "      <td>2019-11-26 16:47:00</td>\n",
       "      <td>2019-11-27 05:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11/27/19</td>\n",
       "      <td>MERV 13-4</td>\n",
       "      <td>5:39</td>\n",
       "      <td>8:53</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>8.5 oz.</td>\n",
       "      <td>8.55 oz.</td>\n",
       "      <td>8 oz.</td>\n",
       "      <td>8 oz.</td>\n",
       "      <td>Data-20191127053638</td>\n",
       "      <td>2019-11-27 05:39:00</td>\n",
       "      <td>2019-11-27 08:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11/27/19</td>\n",
       "      <td>MERV 13-5</td>\n",
       "      <td>8:53</td>\n",
       "      <td>12:50</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>8.55 oz.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8 oz.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data-20191127053638</td>\n",
       "      <td>2019-11-27 08:53:00</td>\n",
       "      <td>2019-11-27 12:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Filter ID Install Time Removal Time  Indoor Temp  Outdoor Temp  \\\n",
       "0   11/20/19       FG-1        14:10        16:12           72            95   \n",
       "1   11/20/19       FG-2        16:16         6:13           72            95   \n",
       "2   11/21/19   MERV 8-1         8:02        10:18           72            95   \n",
       "3   11/21/19   MERV 8-2        10:18        12:38           72            95   \n",
       "4   11/21/19  MERV 13-1        12:38        14:46           72            95   \n",
       "5   11/21/19  MERV 13-2        14:46        16:58           72            95   \n",
       "6   11/21/19   MERV 8-4        16:58         5:30           72            95   \n",
       "7   11/22/19   MERV 8-5         7:51        10:04           72            95   \n",
       "8   11/22/19  MERV 13-4        10:04        13:00           72            95   \n",
       "9   11/22/19  MERV 13-5        13:00        15:32           72            95   \n",
       "10  11/25/19       FG-1         7:40         9:44           70            40   \n",
       "11  11/25/19       FG-2         9:44        13:47           70            40   \n",
       "12  11/25/19   MERV 8-1        13:47        17:46           70            40   \n",
       "13  11/25/19   MERV 8-2        17:46         6:25           70            40   \n",
       "14  11/26/19  MERV 13-1         6:25         9:43           70            40   \n",
       "15  11/26/19  MERV 13-2         9:43        13:03           70            40   \n",
       "16  11/26/19   MERV 8-4        13:03        16:47           70            40   \n",
       "17  11/26/19   MERV 8-5        16:47         5:37           70            40   \n",
       "18  11/27/19  MERV 13-4         5:39         8:53           70            40   \n",
       "19  11/27/19  MERV 13-5         8:53        12:50           70            40   \n",
       "\n",
       "    Outdoor RH Pre 20x20x1 Post 20x20x1 Pre 14x24x1 Post 14x24x1  \\\n",
       "0           50         NaN          NaN         NaN          NaN   \n",
       "1           50         NaN          NaN         NaN          NaN   \n",
       "2           50         NaN          NaN         NaN          NaN   \n",
       "3           50         NaN          NaN         NaN          NaN   \n",
       "4           50         NaN          NaN         NaN          NaN   \n",
       "5           50         NaN          NaN         NaN          NaN   \n",
       "6           50     7.1 oz.      7.1 oz.     7.5 oz.      7.5 oz.   \n",
       "7           50     7.2 oz.     7.25 oz.    7.55 oz.     7.55 oz.   \n",
       "8           50    8.55 oz.     8.55 oz.       8 oz.     7.55 oz.   \n",
       "9           50     8.6 oz.      8.6 oz.    8.05 oz.     8.05 oz.   \n",
       "10          50         NaN          NaN         NaN          NaN   \n",
       "11          50         NaN          NaN         NaN          NaN   \n",
       "12          50         NaN          NaN         NaN          NaN   \n",
       "13          50         NaN          NaN         NaN          NaN   \n",
       "14          50         NaN          NaN         NaN          NaN   \n",
       "15          50         NaN          NaN         NaN          NaN   \n",
       "16          50    7.15 oz.     7.15 oz.     7.5 oz.      7.5 oz.   \n",
       "17          50     7.2 oz.     7.2 oz.     7.55 oz.     7.55 oz.   \n",
       "18          50     8.5 oz.     8.55 oz.       8 oz.        8 oz.   \n",
       "19          50    8.55 oz.          NaN       8 oz.          NaN   \n",
       "\n",
       "                          DAQ File   Install Date Time   Removal Date Time  \n",
       "0              Data-20191120134426 2019-11-20 14:10:00 2019-11-20 16:12:00  \n",
       "1              Data-20191120134426 2019-11-20 16:16:00 2019-11-21 06:13:00  \n",
       "2   Data-20191121080221.dld.0000,1 2019-11-21 08:02:00 2019-11-21 10:18:00  \n",
       "3   Data-20191121080221.dld.0000,1 2019-11-21 10:18:00 2019-11-21 12:38:00  \n",
       "4   Data-20191121080221.dld.0000,1 2019-11-21 12:38:00 2019-11-21 14:46:00  \n",
       "5   Data-20191121080221.dld.0000,1 2019-11-21 14:46:00 2019-11-21 16:58:00  \n",
       "6   Data-20191121080221.dld.0000,1 2019-11-21 16:58:00 2019-11-22 05:30:00  \n",
       "7              Data-20191122074415 2019-11-22 07:51:00 2019-11-22 10:04:00  \n",
       "8              Data-20191122074415 2019-11-22 10:04:00 2019-11-22 13:00:00  \n",
       "9              Data-20191122074415 2019-11-22 13:00:00 2019-11-22 15:32:00  \n",
       "10  Data-20191125071926.dld.0000,1 2019-11-25 07:40:00 2019-11-25 09:44:00  \n",
       "11  Data-20191125071926.dld.0000,1 2019-11-25 09:44:00 2019-11-25 13:47:00  \n",
       "12  Data-20191125071926.dld.0000,1 2019-11-25 13:47:00 2019-11-25 17:46:00  \n",
       "13  Data-20191125071926.dld.0000,1 2019-11-25 17:46:00 2019-11-26 06:25:00  \n",
       "14    Data-20191126061705.dld.0000 2019-11-26 06:25:00 2019-11-26 09:43:00  \n",
       "15    Data-20191126061705.dld.0000 2019-11-26 09:43:00 2019-11-26 13:03:00  \n",
       "16    Data-20191126061705.dld.0000 2019-11-26 13:03:00 2019-11-26 16:47:00  \n",
       "17    Data-20191126061705.dld.0000 2019-11-26 16:47:00 2019-11-27 05:37:00  \n",
       "18             Data-20191127053638 2019-11-27 05:39:00 2019-11-27 08:53:00  \n",
       "19             Data-20191127053638 2019-11-27 08:53:00 2019-11-27 12:50:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bring in the summary table \n",
    "#format the date time inorder to merge with data files\n",
    "summary_df = pd.read_csv(\"Data/3MTestingLog.csv\")\n",
    "summary_df = summary_df.drop(['Table Name'], axis=1)\n",
    "summary_df[\"Install Date Time\"] = pd.to_datetime(summary_df['Date'] + ' ' + summary_df['Install Time'], format=\"%m/%d/%y %H:%M\")\n",
    "summary_df[\"Removal Date Time\"] = pd.to_datetime(summary_df['Date'] + ' ' + summary_df['Removal Time'], format=\"%m/%d/%y %H:%M\")\n",
    "\n",
    "#fix the dates for when the sample was removed the following day after installation.\n",
    "for i in range(len(summary_df['Date'])):\n",
    "    if summary_df['Removal Date Time'][i] < summary_df['Install Date Time'][i]:\n",
    "        summary_df['Removal Date Time'][i] = summary_df['Removal Date Time'][i] + timedelta(days=1)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                         object\n",
       "Filter ID                    object\n",
       "Install Time                 object\n",
       "Removal Time                 object\n",
       "Indoor Temp                   int64\n",
       "Outdoor Temp                  int64\n",
       "Outdoor RH                    int64\n",
       "Pre 20x20x1                  object\n",
       "Post 20x20x1                 object\n",
       "Pre 14x24x1                  object\n",
       "Post 14x24x1                 object\n",
       "DAQ File                     object\n",
       "Install Date Time    datetime64[ns]\n",
       "Removal Date Time    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the testing data \n",
    "#Had to seperate the files because some of them had different headers for the filter pressure drop\n",
    "datafiles1 = [\"Data/Data-20191120134426.csv\", \"Data/Data-20191121080221_0.csv\", \"Data/Data-20191121080221_1.csv\"]\n",
    "\n",
    "datafiles2 = [\"Data/Data-20191122074415.csv\", \"Data/Data-20191125071926_0.csv\", \"Data/Data-20191125071926_1.csv\", \n",
    "             \"Data/Data-20191126061705_0.csv\", \"Data/Data-20191126061705_1.csv\", \"Data/Data-20191127053638.csv\"]\n",
    "\n",
    "usecols1 = ['Date', 'Time', \"Volts\", 'Volts.1', 'Amps', 'Amps.1', 'Volts.2', 'Volts.3', 'Amps.2', 'Amps.3', '0']\n",
    "\n",
    "usecols2 = ['Date', 'Time', \"Volts\", 'Volts.1', 'Amps', 'Amps.1', 'Volts.2', 'Volts.3', 'Amps.2', 'Amps.3', 'In. H2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Data/Data-20191120134426.csv' does not exist: b'Data/Data-20191120134426.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-141c7e6610a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatafiles1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mData1_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mNonZeroData1_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData1_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData1_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Data/Data-20191120134426.csv' does not exist: b'Data/Data-20191120134426.csv'"
     ]
    }
   ],
   "source": [
    "#pullin the first file as a dataframe, pull the desired columns and drop the first row since there are two header rows\n",
    "AllData_df = pd.DataFrame()\n",
    "\n",
    "for file1 in datafiles1: \n",
    "    Data1_df = pd.read_csv(file1, skiprows=1, usecols=usecols1) \n",
    "    \n",
    "    NonZeroData1_df = Data1_df.loc[(Data1_df['Volts']!=0)]\n",
    "\n",
    "    AllData_df = AllData_df.append(NonZeroData1_df, ignore_index=True)\n",
    "    \n",
    "#remove all of the rows with zeros\n",
    "#AllData_df = Data1_df.loc[(Data1_df['Volts']!=0)]\n",
    "\n",
    "#rename the filter pressure drop column to match the rest of the files\n",
    "AllData_df = AllData_df.rename(columns={'0': 'In. H2'})\n",
    "\n",
    "AllData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllData_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in all of the other data files and create one large file while removing all zero values\n",
    "for file in datafiles2:\n",
    "    Data2_df = pd.read_csv(file, skiprows=1, usecols=usecols2)\n",
    "\n",
    "    NonZeroData2_df = Data2_df.loc[(Data2_df['Volts']!=0)]\n",
    "        \n",
    "    AllData_df = AllData_df.append(NonZeroData2_df, ignore_index=True)\n",
    "    \n",
    "\n",
    "AllData_df = AllData_df.rename(columns={'In. H2': 'Filter Pressure Drop (in/H2O)'})\n",
    "    \n",
    "AllData_df['Date and Time'] = pd.to_datetime(AllData_df['Date'] + ' ' + AllData_df['Time'], format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "AllData_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AllData_df['Date and Time'] = pd.to_datetime(AllData_df['Date'] + ' ' + AllData_df['Time'], format=\"%Y/%m/%d %H:%M:%S\")\n",
    "#AllData_df['Date and Time'] = pd.to_datetime(AllData_df['Date'] + ' ' + AllData_df['Time'])\n",
    "\n",
    "ZeroData_df = AllData_df.loc[AllData_df['Volts'] == 0]\n",
    "\n",
    "ZeroData_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating Watts column as Volts+Volts.1 * Amps+Amps.1\n",
    "\n",
    "CalculatedColumns_df = AllData_df.copy()\n",
    "CalculatedColumns_df['Whole Home Power (kW)'] = ((CalculatedColumns_df['Volts']+CalculatedColumns_df['Volts.1']) * (CalculatedColumns_df['Amps']+CalculatedColumns_df['Amps.1']))/1000\n",
    "CalculatedColumns_df['Compressor Power (kW)'] = ((CalculatedColumns_df['Volts.2']+CalculatedColumns_df['Volts.3']) * CalculatedColumns_df['Amps.2'])/1000\n",
    "CalculatedColumns_df['Blower Fan Power (kW)'] = (CalculatedColumns_df['Amps.3'])*120/1000\n",
    "CalculatedColumns_df['Compressor and Fan Power (kW)'] = CalculatedColumns_df['Compressor Power (kW)'] + CalculatedColumns_df['Blower Fan Power (kW)']\n",
    "CalculatedColumns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns in AllData_df by using conditional (mask) and data from summary_df\n",
    "#with using the combined column date and time\n",
    "\n",
    "for i in range(len(summary_df['Filter ID'])):\n",
    "    mask = (CalculatedColumns_df['Date and Time'] >= summary_df['Install Date Time'][i]) & (CalculatedColumns_df['Date and Time'] <= summary_df['Removal Date Time'][i])\n",
    "\n",
    "    #based on the summary table, what was the filter ID during this time fame\n",
    "    CalculatedColumns_df.loc[mask, 'Filter ID'] = summary_df['Filter ID'][i]\n",
    "    \n",
    "    #based on the summary table was the outside of the home during heating or cooling season during this time fame\n",
    "    CalculatedColumns_df.loc[mask, 'Outdoor Temp'] = summary_df['Outdoor Temp'][i]\n",
    "    \n",
    "    #based on the summary table is the filter dirty or clean during this time fame\n",
    "    if (summary_df['Filter ID'][i]=='MERV 8-4') | (summary_df['Filter ID'][i]=='MERV 8-5') | (summary_df['Filter ID'][i]=='MERV 13-4') | (summary_df['Filter ID'][i]=='MERV 13-5'):\n",
    "        CalculatedColumns_df.loc[mask, 'Clean/Dirty'] = 'Dirty'\n",
    "    else:\n",
    "        CalculatedColumns_df.loc[mask, 'Clean/Dirty'] = 'Clean'\n",
    "        \n",
    "    #added a rolling count of seconds the filter was tested for during this time fame\n",
    "    CalculatedColumns_df.loc[mask, 'Cumulative Time in Test (sec)'] = CalculatedColumns_df.loc[mask, 'Filter ID'].rolling(len(CalculatedColumns_df.loc[mask, 'Filter ID'])).count()\n",
    "\n",
    "#remove the na's. This will be the time between the tests\n",
    "FilteredData_df = CalculatedColumns_df.dropna()\n",
    "FilteredData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cut_off = 7200\n",
    "\n",
    "FilterID_CleanDirty_Combined_df = FilteredData_df.copy()\n",
    "FilterID_CleanDirty_Combined_df['Filter ID'] = FilterID_CleanDirty_Combined_df['Filter ID'] + str(' ') + FilterID_CleanDirty_Combined_df['Clean/Dirty']\n",
    "FilterID_CleanDirty_Combined_df = FilterID_CleanDirty_Combined_df.drop(columns=['Clean/Dirty', 'Volts', 'Volts.1', 'Volts.2', 'Volts.3', 'Amps', 'Amps.1', 'Amps.2', 'Amps.3'])\n",
    "FilterID_CleanDirty_Combined_df\n",
    "Grouped_FilterID_CleanDirty = FilterID_CleanDirty_Combined_df[FilterID_CleanDirty_Combined_df['Cumulative Time in Test (sec)'] <= second_cut_off].groupby(['Date and Time', 'Filter ID'])\n",
    "\n",
    "Grouped_FilterID_CleanDirty.sum()\n",
    "\n",
    "FilterID_CleanDirty_df = pd.DataFrame(Grouped_FilterID_CleanDirty.sum())\n",
    "\n",
    "FilterID_CleanDirty_df.to_excel(\"Data/Power and PD over Time.xlsx\", index=True, header=True)\n",
    "\n",
    "FilterID_CleanDirty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVAC Energy vs Time\n",
    "\n",
    "FilteredData_df['Clean/Dirty Filter ID'] = FilteredData_df['Clean/Dirty'] + str(' ') + FilteredData_df['Filter ID']\n",
    "\n",
    "Grouped1 = FilteredData_df[FilteredData_df['Cumulative Time in Test (sec)']<=second_cut_off].groupby(['Outdoor Temp', 'Clean/Dirty Filter ID'])\n",
    "\n",
    "# samplelist = ['Clean FG-1', 'Clean FG-2', 'Clean MERV 8-1', 'Clean MERV 8-2', 'Clean MERV 13-1', 'Clean MERV 13-2',\n",
    "#               'Dirty MERV 8-4', 'Dirty MERV 8-5', 'Dirty MERV 13-4', 'Dirty MERV 13-5']\n",
    "samplelist = list(set(FilteredData_df['Clean/Dirty Filter ID']))\n",
    "\n",
    "# seasons = [40.0, 95.0]\n",
    "seasons = list(set(FilteredData_df['Outdoor Temp']))\n",
    "\n",
    "for season in seasons:\n",
    "    for sample in samplelist:\n",
    "\n",
    "        power_plot = Grouped1.get_group((season, sample)).plot(kind='line', \n",
    "                                                  x='Cumulative Time in Test (sec)', \n",
    "                                                  y='Compressor and Fan Power (kW)',\n",
    "                                                  ylim=(0,6.1), legend=False, \n",
    "                                                  title='Outdoor Temp of ' + str(season) + ' with a ' + sample\n",
    "                                                 )\n",
    "        power_plot.set_ylabel('Compressor and Fan Power (kW)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"Images/Energy Plots/\" + str(season) + \" \" + str(sample) + \" Power Cycling over Time.png\")\n",
    "        \n",
    "        PD_plot = Grouped1.get_group((season, sample)).plot(kind='line', \n",
    "                                                  x='Cumulative Time in Test (sec)', \n",
    "                                                  y='Filter Pressure Drop (in/H2O)',\n",
    "                                                  ylim=(0,0.30), legend=False, \n",
    "                                                  title='Outdoor Temp of ' + str(season) + ' with a ' + sample\n",
    "                                                 )\n",
    "        PD_plot.set_ylabel('Filter Pressure Drop (in/H2O)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"Images/Pressure Drop Plots/\" + str(season) + \" \" + str(sample) + \" Pressure Drops over Time.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVAC Energy vs Time\n",
    "\n",
    "FilteredData_df['Clean/Dirty Filter ID'] = FilteredData_df['Clean/Dirty'] + str(' ') + FilteredData_df['Filter ID']\n",
    "\n",
    "Grouped1 = FilteredData_df[FilteredData_df['Cumulative Time in Test (sec)']<=second_cut_off].groupby(['Outdoor Temp', 'Clean/Dirty Filter ID'])\n",
    "\n",
    "# samplelist = ['Clean MERV 13-1', 'Clean MERV 13-2', 'Clean FG-1', 'Clean FG-2', 'Clean MERV 8-1', 'Clean MERV 8-2', \n",
    "#               'Dirty MERV 13-4', 'Dirty MERV 13-5', 'Dirty MERV 8-4', 'Dirty MERV 8-5']\n",
    "samplelist = list(set(FilteredData_df['Clean/Dirty Filter ID']))\n",
    "\n",
    "# seasons = [40.0, 95.0]\n",
    "seasons = list(set(FilteredData_df['Outdoor Temp']))\n",
    "\n",
    "for season in seasons:\n",
    "    for sample in samplelist:\n",
    "\n",
    "        power_plot = Grouped1.get_group((season, sample)).plot(kind='line', \n",
    "                                                  x='Cumulative Time in Test (sec)', \n",
    "                                                  y='Compressor and Fan Power (kW)',\n",
    "                                                  ylim=(0,6.1), legend=False, \n",
    "                                                  title='Outdoor Temp of ' + str(season) + ' with a ' + sample\n",
    "                                                 )\n",
    "#         power_plot.set_ylabel('Compressor and Fan Power (kW)')\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(\"Images/Energy Plots/\" + str(season) + \" \" + str(sample) + \" Power Cycling over Time.png\")\n",
    "        \n",
    "        power_plot = Grouped1.get_group((season, sample)).plot(kind='line', \n",
    "                                                  x='Cumulative Time in Test (sec)', \n",
    "                                                  y='Filter Pressure Drop (in/H2O)',\n",
    "                                                  ylim=(0,0.30), legend=False, \n",
    "                                                  title='Outdoor Temp of ' + str(season) + ' with a ' + sample\n",
    "                                                 )\n",
    "#         power_plot.set_ylabel('Filter Pressure Drop (in/H2O)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"Images/Energy and Pressure Over Time/\" + str(season) + \" \" + str(sample) + \" Pressure Drops over Time.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all non zero pressure drop values\n",
    "\n",
    "pressuredrop_df = FilteredData_df[FilteredData_df['Cumulative Time in Test (sec)']<=second_cut_off]\n",
    "\n",
    "pressuredrop_df = pressuredrop_df[pressuredrop_df['Filter Pressure Drop (in/H2O)']!=0.0]\n",
    "\n",
    "pressuredrop_df = pressuredrop_df.drop(columns=['Volts', 'Volts.1', 'Amps', 'Amps.1', 'Volts.2', 'Volts.3', 'Amps.2', 'Amps.3'])\n",
    "  \n",
    "pressuredrop_df['Clean/Dirty Filter ID'] = pressuredrop_df['Clean/Dirty'] + str(' ') + pressuredrop_df['Filter ID']\n",
    "    \n",
    "pressuredrop_cooling_df = pressuredrop_df[pressuredrop_df['Outdoor Temp']==95.0]\n",
    "\n",
    "pressuredrop_heating_df = pressuredrop_df[pressuredrop_df['Outdoor Temp']==40.0]\n",
    "\n",
    "pressuredrop_heating_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering Energy consumed by using groupby()\n",
    "#Group the data for only the first 2 hours the filter was tested\n",
    "second_cut_off = 7200\n",
    "Grouped_df = FilteredData_df[FilteredData_df['Cumulative Time in Test (sec)'] <= second_cut_off].groupby(['Outdoor Temp','Clean/Dirty','Filter ID'])\n",
    "\n",
    "#Calculate the Energy and convert from seconds to hours  \n",
    "Energy_Consumped_df = pd.DataFrame((Grouped_df['Whole Home Power (kW)'].sum())/(3600))\n",
    "Energy_Consumped_df = Energy_Consumped_df.rename(columns={'Whole Home Power (kW)': 'Whole Home Energy (kWh)'})\n",
    "\n",
    "Energy_Consumped_df['Compressor Energy (kWh)'] = (Grouped_df['Compressor Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_df['Blower Fan Energy (kWh)'] = (Grouped_df['Blower Fan Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_df['Compressor and Fan Energy (kWh)'] = (Grouped_df['Compressor and Fan Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_df.to_excel('Data/Energy Consumption per Filter.xlsx')\n",
    "\n",
    "Energy_Consumped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new group with just values during the heating season\n",
    "#Gathering Energy consumed by using groupby()\n",
    "#Group the data for only the first 2 hours the filter was tested\n",
    "second_cut_off = 7200\n",
    "Heating_df = FilteredData_df[FilteredData_df['Outdoor Temp'] == 40.0]\n",
    "GroupedHeating_df = Heating_df[Heating_df['Cumulative Time in Test (sec)'] <= second_cut_off].groupby(['Clean/Dirty','Filter ID'])\n",
    "\n",
    "#Calculate the Energy and convert from seconds to hours  \n",
    "Energy_Consumped_Heating_df = pd.DataFrame((GroupedHeating_df['Whole Home Power (kW)'].sum())/(3600))\n",
    "Energy_Consumped_Heating_df = Energy_Consumped_Heating_df.rename(columns={'Whole Home Power (kW)': 'Whole Home Energy (kWh)'})\n",
    "\n",
    "Energy_Consumped_Heating_df['Compressor Energy (kWh)'] = (GroupedHeating_df['Compressor Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_Heating_df['Blower Fan Energy (kWh)'] = (GroupedHeating_df['Blower Fan Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_Heating_df['Compressor and Fan Energy (kWh)'] = (GroupedHeating_df['Compressor and Fan Power (kW)'].sum())/(3600)\n",
    "\n",
    "# Try this instead of creating a new column and doing .sort_values()\n",
    "# df.reindex(['Mon', 'Wed', 'Thu', 'Fri'], level='day')\n",
    "Energy_Consumped_Heating_df = Energy_Consumped_Heating_df.reindex(['FG-1', 'FG-2', 'MERV 8-1', 'MERV 8-2', 'MERV 13-1', 'MERV 13-2',\n",
    "                                    'MERV 8-4', 'MERV 8-5', 'MERV 13-4', 'MERV 13-5'], level='Filter ID')\n",
    "\n",
    "# Energy_Consumped_Heating_df['Sort Column'] = [4, 5, 0, 1, 2, 3, 8, 9, 6, 7]\n",
    "\n",
    "# Energy_Consumped_Heating_df = Energy_Consumped_Heating_df.sort_values('Sort Column')\n",
    "\n",
    "Energy_Consumped_Heating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new group with just values during the cooling season\n",
    "#Gathering Energy consumed by using groupby()\n",
    "#Group the data for only the first 2 hours the filter was tested\n",
    "second_cut_off = 7200\n",
    "Cooling_df = FilteredData_df[FilteredData_df['Outdoor Temp'] == 95.0]\n",
    "time_cut_off_Cooling_df = Cooling_df[Cooling_df['Cumulative Time in Test (sec)'] <= second_cut_off]\n",
    "GroupedCooling_df = Cooling_df[Cooling_df['Cumulative Time in Test (sec)'] <= second_cut_off].groupby(['Clean/Dirty','Filter ID'])\n",
    "\n",
    "#Calculate the Energy and convert from seconds to hours  \n",
    "Energy_Consumped_Cooling_df = pd.DataFrame((GroupedCooling_df['Whole Home Power (kW)'].sum())/(3600))\n",
    "Energy_Consumped_Cooling_df = Energy_Consumped_Cooling_df.rename(columns={'Whole Home Power (kW)': 'Whole Home Energy (kWh)'})\n",
    "\n",
    "Energy_Consumped_Cooling_df['Compressor Energy (kWh)'] = (GroupedCooling_df['Compressor Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_Cooling_df['Blower Fan Energy (kWh)'] = (GroupedCooling_df['Blower Fan Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_Cooling_df['Compressor and Fan Energy (kWh)'] = (GroupedCooling_df['Compressor and Fan Power (kW)'].sum())/(3600)\n",
    "\n",
    "Energy_Consumped_Cooling_df = Energy_Consumped_Cooling_df.reindex(['FG-1', 'FG-2', 'MERV 8-1', 'MERV 8-2', 'MERV 13-1', 'MERV 13-2',\n",
    "                                    'MERV 8-4', 'MERV 8-5', 'MERV 13-4', 'MERV 13-5'], level='Filter ID')\n",
    "\n",
    "# Energy_Consumped_Cooling_df['Sort Column'] = [4, 5, 0, 1, 2, 3, 8, 9, 6, 7]\n",
    "\n",
    "# Energy_Consumped_Cooling_df = Energy_Consumped_Cooling_df.sort_values('Sort Column')\n",
    "\n",
    "Energy_Consumped_Cooling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Grouped Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph pressure drop across filter results from the heating season\n",
    "pressuredrop_heating_df\n",
    "\n",
    "order = ['Clean FG-1', 'Clean FG-2', 'Clean MERV 8-1', 'Clean MERV 8-2', 'Clean MERV 13-1', 'Clean MERV 13-2', \n",
    "         'Dirty MERV 8-4', 'Dirty MERV 8-5', 'Dirty MERV 13-4', 'Dirty MERV 13-5']\n",
    "\n",
    "pressuredrop_heating_group = pressuredrop_heating_df.groupby(['Clean/Dirty Filter ID'])\n",
    "\n",
    "pressuredrop_heating_group_df = pressuredrop_heating_group.mean()\n",
    "pressuredrop_heating_group_df = pressuredrop_heating_group_df.reindex(order)\n",
    "\n",
    "pd_heating_group_err_df = pressuredrop_heating_group['Filter Pressure Drop (in/H2O)'].std()\n",
    "pd_heating_group_err_df = pd_heating_group_err_df.reindex(order)\n",
    "\n",
    "error = list(pd_heating_group_err_df)\n",
    "\n",
    "heat_PD_plot= pressuredrop_heating_group_df['Filter Pressure Drop (in/H2O)'].plot(kind='bar',\n",
    "                                                                    color=['grey', 'grey', 'r', 'r', 'b', 'b', 'lightcoral', 'lightcoral', 'cornflowerblue', 'cornflowerblue'],\n",
    "                                                                    figsize = (14,7),\n",
    "                                                                    yerr=error\n",
    "                                                                   )\n",
    "\n",
    "plt.xlabel('Filters Tested')\n",
    "plt.title('Heating Season: Pressure Drop Averages')\n",
    "heat_PD_plot.set_ylabel('Pressure Drop of Filter (in/H2O)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/Pressure Drop Plots/HeatingSeason_Pressure_Drop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph pressure drop across filter results from the cooling season\n",
    "pressuredrop_cooling_df\n",
    "\n",
    "pressuredrop_cooling_group = pressuredrop_cooling_df.groupby(['Clean/Dirty Filter ID'])\n",
    "\n",
    "pressuredrop_cooling_group_df = pressuredrop_cooling_group.mean()\n",
    "pressuredrop_cooling_group_df = pressuredrop_cooling_group_df.reindex(order)\n",
    "\n",
    "pd_cooling_group_err_df = pressuredrop_cooling_group['Filter Pressure Drop (in/H2O)'].std()\n",
    "pd_cooling_group_err_df = pd_cooling_group_err_df.reindex(order)\n",
    "\n",
    "error = list(pd_cooling_group_err_df)\n",
    "\n",
    "pressuredrop_cooling_group_df\n",
    "\n",
    "cool_PD_plot = pressuredrop_cooling_group_df['Filter Pressure Drop (in/H2O)'].plot(kind='bar',\n",
    "                                                                    color=['grey', 'grey', 'r', 'r', 'b', 'b', 'lightcoral', 'lightcoral', 'cornflowerblue', 'cornflowerblue'],\n",
    "                                                                    yerr=error,\n",
    "                                                                    figsize = (14,7)\n",
    "                                                                   )\n",
    "\n",
    "plt.xlabel('Filters Tested')\n",
    "plt.title('Cooling Season: Pressure Drop Averages')\n",
    "cool_PD_plot.set_ylabel('Pressure Drop of Filter (in/H2O)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/Pressure Drop Plots/CoolingSeason_Pressure_Drop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph Energy_Consumped_Heating_df results\n",
    "\n",
    "heat_HVACenergy_plot = Energy_Consumped_Heating_df['Compressor and Fan Energy (kWh)'].plot(kind='bar', \n",
    "                                                                    color=['grey', 'grey', 'r', 'r', 'b', 'b', 'lightcoral', 'lightcoral', 'cornflowerblue', 'cornflowerblue'],\n",
    "                                                                    figsize = (14,7)\n",
    "                                                                   )\n",
    "plt.xlabel('Filters Tested')\n",
    "plt.xticks(range(len(order)), order)\n",
    "plt.title('Heating Season: HVAC Energy Consumed')\n",
    "heat_HVACenergy_plot.set_ylabel('Compressor and Fan Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/Energy Plots/Heating_Season_HVAC_Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph Energy_Consumped_Cooling_df results for HVAC unit\n",
    "\n",
    "cool_HVACenergy_plot = Energy_Consumped_Cooling_df['Compressor and Fan Energy (kWh)'].plot(kind='bar', \n",
    "                                                                    color=['grey', 'grey', 'r', 'r', 'b', 'b', 'lightcoral', 'lightcoral', 'cornflowerblue', 'cornflowerblue'],\n",
    "                                                                    figsize=(14,7)\n",
    "                                                                   )\n",
    "\n",
    "cool_HVACenergy_plot.set_ylabel('Compressor and Fan Energy (kWh)')\n",
    "plt.xlabel('Filters Tested')\n",
    "plt.xticks(range(len(order)), order)\n",
    "plt.title('Cooling Season: HVAC Energy Consumed')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/Energy Plots/Cooling_Season_HVAC_Energy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph Energy_Consumped_Heating_df results for Whole Home\n",
    "\n",
    "heat_HomeEnergy_plot = Energy_Consumped_Heating_df['Whole Home Energy (kWh)'].plot(kind='bar', \n",
    "                                                            color=['grey', 'grey', 'r', 'r', 'b', 'b', 'lightcoral', 'lightcoral', 'cornflowerblue', 'cornflowerblue'],\n",
    "                                                            figsize=(14,7)\n",
    "                                                                   )\n",
    "plt.xlabel('Filters Tested')\n",
    "plt.xticks(range(len(order)), order)\n",
    "plt.title('Heating Season: Whole Home Energy Consumed')\n",
    "heat_HomeEnergy_plot.set_ylabel('Whole Home Energy(kWh)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/Energy Plots/Heating_Season_WholeHome_Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph Energy_Consumped_Cooling_df results for Whole Home\n",
    "\n",
    "cool_HomeEnergy_plot = Energy_Consumped_Cooling_df['Whole Home Energy (kWh)'].plot(kind='bar',\n",
    "                                                            y='Whole Home Energy (kWh)',\n",
    "                                                            color=['grey', 'grey', 'r', 'r', 'b', 'b', 'lightcoral', 'lightcoral', 'cornflowerblue', 'cornflowerblue'], \n",
    "                                                            figsize=(14,7)\n",
    "                                                                   )\n",
    "plt.xlabel('Filters Tested')\n",
    "plt.xticks(range(len(order)), order)\n",
    "plt.title('Cooling Season: Whole Home Energy Consumed')\n",
    "cool_HomeEnergy_plot.set_ylabel('Whole Home Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Images/Energy Plots/Cooling_Season_WholeHome_Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
